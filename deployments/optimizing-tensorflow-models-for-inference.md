# Optimizing TensorFlow Models for Inference

Gradient supports deployment of models compatible with industry standards. There are a variety of optimizations you can perform on Tensorflow neural network graphs to reduce their size and latency for inference. Because we use [TF Serving](https://github.com/tensorflow/serving) for TensorFlow models, we are able to support deployment of these optimized graphs.

